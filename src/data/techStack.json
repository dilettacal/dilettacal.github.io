{
  "_notice": "‚ö†Ô∏è PERSONAL DATA - This content belongs to Diletta Calussi and must NOT be used by others. Replace with your own information. See src/data/README.md",
  "viewSkillBars": true,
  "subtitle": "üìä What and where I have been focusing on the last years üéØ",
  "hint": "For more details, click on the bars. ‚¨áÔ∏è",
  "maxYears": 7,
  "experience": [
    {
      "Stack": "Data Engineering",
      "periods": [
        {
          "start": 1,
          "duration": 6
        }
      ],
      "details": "I design and operate data systems that combine batch and streaming processing, primarily on Azure. \n        Data ingestion is event-driven or push/pull-based, integrating structured, semi-structured, and unstructured sources into Python-based pipelines and microservice architectures. \n        Transformations and aggregations are implemented according to use-case complexity, with storage spanning Redis, MongoDB, and PostgreSQL. \n        Monitoring and validation are handled through New Relic and automated testing to maintain reliability, scalability, and consistency across environments.",
      "icons": [
        {
          "fontAwesomeClassname": "fab fa-python",
          "name": "Python"
        },
        {
          "customIcon": "azure",
          "name": "Azure"
        },
        {
          "customIcon": "pandas",
          "name": "Pandas"
        },
        {
          "customIcon": "pyspark",
          "name": "PySpark"
        },
        {
          "customIcon": "databricks",
          "name": "Databricks"
        },
        {
          "customIcon": "postgresql",
          "name": "PostgreSQL"
        },
        {
          "customIcon": "redis",
          "name": "Redis"
        },
        {
          "customIcon": "apachekafka",
          "name": "Apache Kafka"
        },
        {
          "customIcon": "mongodb",
          "name": "MongoDB"
        },
        {
          "customIcon": "newrelic",
          "name": "New Relic"
        },
        {
          "customIcon": "pytest",
          "name": "Pytest"
        }
      ]
    },
    {
      "Stack": "LLM Engineering & NLP/NLU",
      "periods": [
        {
          "start": 0,
          "duration": 2
        },
        {
          "start": 2,
          "duration": 3
        },
        {
          "start": 5,
          "duration": 2
        }
      ],
      "details": "I develop Generative AI solutions focused on chatbots, prediction, summarization, and automation. My work includes agent-based systems for project management using CrewAI and LangChain, integrating open-source and SDK-based models such as OpenAI, Anthropic, and Ollama. \n        In the automotive domain, I have built multilingual NLU models (German/English) for in-car assistants covering a wide range of infotainment and control functions, including but not limited to navigation and climate settings.\n        My experience spans rule-based, grammar-driven, and neural approaches (PyTorch) for intent classification and entity extraction, as well as Neural Machine Translation using sequence-to-sequence architectures like attention-based LSTMs and Transformers.",
      "icons": [
        {
          "fontAwesomeClassname": "fab fa-python",
          "name": "Python"
        },
        {
          "customIcon": "openai",
          "name": "OpenAI"
        },
        {
          "customIcon": "anthropic",
          "name": "Anthropic"
        },
        {
          "customIcon": "ollama",
          "name": "Ollama"
        },
        {
          "customIcon": "spacy",
          "name": "spaCy"
        },
        {
          "customIcon": "langchain",
          "name": "LangChain"
        },
        {
          "customIcon": "crewai",
          "name": "CrewAI"
        },
        {
          "customIcon": "huggingface",
          "name": "HuggingFace"
        },
        {
          "customIcon": "pytorch",
          "name": "PyTorch"
        },
        {
          "customIcon": "jupyter",
          "name": "Jupyter"
        },
        {
          "fontAwesomeClassname": "fa-brands fa-java",
          "name": "Java"
        }
      ]
    },
    {
      "Stack": "Data Science and Analytics",
      "periods": [
        {
          "start": 1,
          "duration": 6
        }
      ],
      "details": "I perform exploratory data analysis to assess data integrity, detect anomalies, and derive initial insights that inform downstream modeling and system design. \n        My work combines descriptive statistics, visualization, and hypothesis-driven investigation to understand data behavior and edge cases before formal pipeline integration. \n        Typical tasks include profiling large telemetry and geospatial datasets, verifying schema consistency, validating business metrics, and identifying data quality issues early in the development cycle. \n        Analyses are carried out primarily in Python using pandas, NumPy, and visualization libraries to support both ad-hoc studies and structured reporting.",
      "icons": [
        {
          "fontAwesomeClassname": "fab fa-python",
          "name": "Python"
        },
        {
          "customIcon": "pytorch",
          "name": "PyTorch"
        },
        {
          "customIcon": "jupyter",
          "name": "Jupyter"
        },
        {
          "customIcon": "numpy",
          "name": "NumPy"
        },
        {
          "customIcon": "pandas",
          "name": "Pandas"
        },
        {
          "customIcon": "databricks",
          "name": "Databricks"
        }
      ]
    },
    {
      "Stack": "Cloud and DevOps",
      "periods": [
        {
          "start": 2,
          "duration": 5
        }
      ],
      "details": "I design, deploy, and maintain cloud-native systems on Azure and AWS, focusing on scalability, automation, and observability. \n        Infrastructure is defined as code using Bicep and Terraform to ensure reproducible, version-controlled environments. \n        Containerization with Docker and orchestration via Kubernetes enable modular, microservice-based architectures. \n        CI/CD pipelines built with GitHub Actions automate build, test, and release processes, while continuous monitoring ensures high availability and operational stability across environments.",
      "icons": [
        {
          "customIcon": "kubernetes",
          "name": "Kubernetes"
        },
        {
          "fontAwesomeClassname": "fab fa-docker",
          "name": "Docker"
        },
        {
          "customIcon": "azure",
          "name": "Azure"
        },
        {
          "fontAwesomeClassname": "fab fa-aws",
          "name": "AWS"
        },
        {
          "customIcon": "terraform",
          "name": "Terraform"
        },
        {
          "customIcon": "githubactions",
          "name": "GitHub Actions"
        }
      ]
    },
    {
      "Stack": "Frontend & Design",
      "periods": [
        {
          "start": 5,
          "duration": 2
        }
      ],
      "details": "I'm currently exploring frontend development by creating lightweight interfaces to visualize data, test AI ideas, and prototype concepts. \n        For GenAI projects, I use Gradio and Streamlit to build quick interactive demos. When needed, I work with React, Next.js, and Tailwind CSS for responsive, maintainable UIs. \n        In my self-publishing projects, I use Canva and Adobe InDesign for layout and design, ensuring clean, consistent, and visually engaging results.",
      "icons": [
        {
          "fontAwesomeClassname": "fab fa-react",
          "name": "React"
        },
        {
          "customIcon": "nextdotjs",
          "name": "Next.js"
        },
        {
          "customIcon": "tailwindcss",
          "name": "Tailwind CSS"
        },
        {
          "customIcon": "canva",
          "name": "Canva"
        },
        {
          "customIcon": "adobeindesign",
          "name": "Adobe InDesign"
        },
        {
          "customIcon": "gradio",
          "name": "Gradio"
        },
        {
          "customIcon": "streamlit",
          "name": "Streamlit"
        }
      ]
    }
  ],
  "displayCodersrank": false
}

