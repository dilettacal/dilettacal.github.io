{
  "_notice": "‚ö†Ô∏è PERSONAL DATA - This content belongs to Diletta Calussi and must NOT be used by others. Replace with your own information. See src/data/README.md",
  "viewSkillBars": true,
  "subtitle": "üìä What and where I have been focusing on the last years üéØ",
  "hint": "For more details, click on the bars. ‚¨áÔ∏è",
  "maxYears": 7,
  "experience": [
    {
      "Stack": "Data Engineering",
      "periods": [
        {
          "start":3,
          "duration": 4
        }
      ],
      "details": "I design and operate robust data platforms that process both batch and streaming workloads across diverse cloud environments. I can build scalable ingestion and transformation pipelines, implement event-driven architectures, and design data ecosystems using serverless, containerized, or hybrid deployment models. My expertise covers automated testing for data quality, observability and monitoring for operational transparency, and performance optimization to ensure resilience and scalability in production.",
      "icons": [
        {
          "fontAwesomeClassname": "fab fa-python",
          "name": "Python"
        },
        {
          "customIcon": "azure",
          "name": "Azure"
        },
        {
          "customIcon": "pandas",
          "name": "Pandas"
        },
        {
          "customIcon": "pyspark",
          "name": "PySpark"
        },
        {
          "customIcon": "databricks",
          "name": "Databricks"
        },
        {
          "customIcon": "postgresql",
          "name": "PostgreSQL"
        },
        {
          "customIcon": "redis",
          "name": "Redis"
        },
        {
          "customIcon": "apachekafka",
          "name": "Apache Kafka"
        },
        {
          "customIcon": "mongodb",
          "name": "MongoDB"
        },
        {
          "customIcon": "newrelic",
          "name": "New Relic"
        },
        {
          "customIcon": "pytest",
          "name": "Pytest"
        },
        {
          "customIcon": "sqlalchemy",
          "name": "SQLAlchemy"
        }
      ]
    },
    {
      "Stack": "LLM Engineering & NLP/NLU",
      "periods": [
        {
          "start": 0,
          "duration": 2
        },
        {
          "start": 2,
          "duration": 3
        },
        {
          "start": 5,
          "duration": 2
        }
      ],
      "details": "I develop and integrate Large Language Model‚Äìbased systems for applications such as summarization, prediction, and agentic automation. I can design prompt- and retrieval-based architectures, orchestrate multi-agent workflows, and combine open-source and API-based models within secure, monitored environments. My background spans linguistic modeling, hybrid NLU pipelines, and end-to-end deployment of GenAI solutions from prototype to production.",
      "icons": [
        {
          "fontAwesomeClassname": "fab fa-python",
          "name": "Python"
        },
        {
          "customIcon": "openai",
          "name": "OpenAI"
        },
        {
          "customIcon": "anthropic",
          "name": "Anthropic"
        },
        {
          "customIcon": "ollama",
          "name": "Ollama"
        },
        {
          "customIcon": "spacy",
          "name": "spaCy"
        },
        {
          "customIcon": "langchain",
          "name": "LangChain"
        },
        {
          "customIcon": "crewai",
          "name": "CrewAI"
        },
        {
          "customIcon": "wandb",
          "name": "Weights and Biases"
        },
        {
          "customIcon": "huggingface",
          "name": "HuggingFace"
        },
        {
          "customIcon": "pytorch",
          "name": "PyTorch"
        },
        {
          "customIcon": "jupyter",
          "name": "Jupyter"
        },
        {
          "fontAwesomeClassname": "fa-brands fa-java",
          "name": "Java"
        }
      ]
    },
    {
      "Stack": "Data Science and Analytics",
      "periods": [
        {
          "start": 1,
          "duration": 6
        }
      ],
      "details": "I analyze complex and large-scale datasets to uncover patterns, validate data integrity, and derive actionable insights that inform model and system design. I can perform exploratory and statistical analysis, anomaly detection, and feature evaluation across structured and unstructured data.",
      "icons": [
        {
          "fontAwesomeClassname": "fab fa-python",
          "name": "Python"
        },
        {
          "customIcon": "pytorch",
          "name": "PyTorch"
        },
        {
          "customIcon": "jupyter",
          "name": "Jupyter"
        },
        {
          "customIcon": "numpy",
          "name": "NumPy"
        },
        {
          "customIcon": "pandas",
          "name": "Pandas"
        },
        {
          "customIcon": "databricks",
          "name": "Databricks"
        }
      ]
    },
    {
      "Stack": "Cloud and DevOps",
      "periods": [
        {
          "start": 3,
          "duration": 4
        }
      ],
      "details": "I design, deploy, and operate cloud-native infrastructures across multiple providers with a focus on automation, scalability, and security. I can build CI/CD pipelines, define infrastructure as code, and manage workloads using serverless, containerized, and distributed architectures.",
      "icons": [
        {
          "customIcon": "kubernetes",
          "name": "Kubernetes"
        },
        {
          "fontAwesomeClassname": "fab fa-docker",
          "name": "Docker"
        },
        {
          "customIcon": "azure",
          "name": "Azure"
        },
        {
          "fontAwesomeClassname": "fab fa-aws",
          "name": "AWS"
        },
        {
          "customIcon": "terraform",
          "name": "Terraform"
        },
        {
          "customIcon": "githubactions",
          "name": "GitHub Actions"
        }
      ]
    },
    {
      "Stack": "Frontend & Design",
      "periods": [
        {
          "start": 5,
          "duration": 2
        }
      ],
      "details": "I build lightweight interfaces to visualize data, prototype AI concepts, and demonstrate GenAI workflows. For LLM applications, I use Gradio and Streamlit to develop interactive demos. When needed, I rely on React, Next.js, and Tailwind CSS for production-ready front-ends. In self-publishing projects, I design layouts in Canva and Adobe InDesign, ensuring clean, consistent, and visually appealing results.",
      "icons": [
        {
          "fontAwesomeClassname": "fab fa-react",
          "name": "React"
        },
        {
          "customIcon": "nextdotjs",
          "name": "Next.js"
        },
        {
          "customIcon": "tailwindcss",
          "name": "Tailwind CSS"
        },
        {
          "customIcon": "canva",
          "name": "Canva"
        },
        {
          "customIcon": "adobeindesign",
          "name": "Adobe InDesign"
        },
        {
          "customIcon": "gradio",
          "name": "Gradio"
        },
        {
          "customIcon": "streamlit",
          "name": "Streamlit"
        }
      ]
    }
  ],
  "displayCodersrank": false
}

